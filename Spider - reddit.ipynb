{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit https://www.reddit.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "搜尋關鍵字 :  covid19\n",
      "要顯示前幾篇? :  1\n",
      "要顯示多少留言? :  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------- TOP  1  start : ----------------------------------------------\n",
      "\n",
      "Title :  Groomer closed due to Covid19. Wife told me to trim the dog. Hold my beer. \n",
      "\n",
      "Href :  /r/aww/comments/fsipjl/groomer_closed_due_to_covid19_wife_told_me_to/ \n",
      "\n",
      "\n",
      " Buttstuffs69  :\n",
      "\n",
      " The toupee really makes it\n",
      "\n",
      " SchnoodleDoodleDo  :\n",
      "\n",
      " 'The toupee really makes it...so momma said i need a trim,but groomer place was closedthe job, it then, was passed to 'him'n daddy said 'Here goes...!'n with that, he begin the buzz -ATTAC the shaggy mop!he did not know what 'grooming' was -my fur began to drop :@(n just when i thought All was lost -mom dint know what to say...dad smiled n said, 'Look! Free of cost!'n left me a toupee !n now, i'm feelin pretty good -at last the clipping stop!my dad - he did the Best he could...n left some on the top =;@)❤️I’m a big fan of the toupee... but I really wanted a Mohawk\n",
      "\n",
      " Mad_Hatter_92  :\n",
      "\n",
      " Bro he has a sick fade.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "\n",
    "list_hrefs = []\n",
    "list_titles = []\n",
    "\n",
    "search_word = \"https://www.reddit.com/search/?q=\"+input(\"搜尋關鍵字 : \")\n",
    "top_x_threshold = input(\"要顯示前幾篇? : \")\n",
    "show_comment = input(\"要顯示多少留言? : \")\n",
    "\n",
    "while len(list_hrefs) == 0:\n",
    "    html = urlopen(search_word).read().decode('utf-8',errors='ignore')\n",
    "    soup = BeautifulSoup(html, features='lxml')\n",
    "    \n",
    "    a_href=soup.find_all('a', {'data-click-id': re.compile(\"body\")}) \n",
    "    for href in a_href:\n",
    "        list_hrefs.append(href['href'])\n",
    "\n",
    "    a_titles=soup.find_all('span', {'style': re.compile(\"font-weight:normal\")}) \n",
    "    for title in a_titles:\n",
    "        list_titles.append(title.text)\n",
    "    \n",
    "def repeat_run(i,show_,list_hrefs,list_titles):\n",
    "    top_x = i\n",
    "    list_href = list_hrefs\n",
    "    list_title = list_titles\n",
    "    show_comments = show_\n",
    "    if(top_x < int(top_x_threshold)):\n",
    "        try:\n",
    "            html = urlopen(\"https://www.reddit.com\"+ list_hrefs[top_x]).read().decode('utf-8',errors='ignore')\n",
    "            new_comment = []\n",
    "            if len(html) != 0:\n",
    "                soup = BeautifulSoup(html, features='lxml')\n",
    "                a_comments = soup.find_all('p')\n",
    "                for comment in a_comments:\n",
    "                    new_comment.append(comment.text)\n",
    "                a_tags=soup.find_all('script', {'id': re.compile(\"data\")}) \n",
    "                for tag in a_tags:\n",
    "                    from_position = 0\n",
    "                    author_lists = []\n",
    "                    author_start_position_lists = []\n",
    "                    for i in range(len(new_comment)):\n",
    "                        author_lists.append(tag.text[from_position+tag.text[from_position:].find(\"\\\"author\\\":\")+10:from_position+tag.text[from_position:].find(\"\\\",\\\"authorId\\\"\")])\n",
    "                        author_start_position_lists.append(from_position+tag.text[from_position:].find(\"\\\"author\\\":\")+10)\n",
    "                        from_position = from_position+tag.text[from_position:].find(\"\\\",\\\"authorId\\\"\")+12\n",
    "\n",
    "                    from_position = 0\n",
    "                    check_auther = 1\n",
    "                    comment_position_lists = []\n",
    "                    for i in range(len(new_comment)):\n",
    "\n",
    "                        if( from_position+tag.text[from_position:].find(\"}],\\\"e\\\"\") < author_start_position_lists[check_auther]):\n",
    "                            comment_position_lists.append(check_auther-1)\n",
    "                        else:\n",
    "                            check_auther+=1\n",
    "                            comment_position_lists.append(check_auther-1)\n",
    "                        from_position = from_position+tag.text[from_position:].find(\"}],\\\"e\\\"\")+7\n",
    "            \n",
    "            list_comment = ['' for i in range(len(set(comment_position_lists)))]\n",
    "            for sentences in range(len(new_comment)): #\n",
    "                list_comment[comment_position_lists[sentences]]+=new_comment[sentences]\n",
    "            print('---------------------------------------------- TOP ',top_x+1,' start : ----------------------------------------------\\n')\n",
    "            print('Title : ',list_title[top_x],'\\n')\n",
    "            print('Href : ',list_href[top_x],'\\n')\n",
    "            not_yet = True\n",
    "            add_sentences = 0\n",
    "            have_comment = False\n",
    "            for each in range(show_comments):\n",
    "                if(not_yet):\n",
    "                    if(list_comment[each].find(tag.text[tag.text.find(\"document\\\":[{\\\"c\\\":[{\\\"e\\\":\\\"text\\\",\\\"t\\\":\\\"\")+34:tag.text.find(\"document\\\":[{\\\"c\\\":[{\\\"e\\\":\\\"text\\\",\\\"t\\\":\\\"\")+44])==-1):\n",
    "                        not_yet = True\n",
    "                        have_comment = True\n",
    "                        add_sentences +=1\n",
    "                    else:\n",
    "                        not_yet=False\n",
    "            if(have_comment):\n",
    "                print('comment : \\n')\n",
    "                for each_comment in range(add_sentences):\n",
    "                    print(list_comment[each_comment],'\\n')    \n",
    "            for each in range(show_comments):\n",
    "                print('\\n',author_lists[each],' :\\n\\n',list_comment[each+add_sentences])\n",
    "            print('\\n')\n",
    "            repeat_run(top_x+1,int(show_comments),list_hrefs,list_titles)\n",
    "        except:\n",
    "            repeat_run(top_x,int(show_comments),list_hrefs,list_titles)\n",
    "repeat_run(0,int(show_comment),list_hrefs,list_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
