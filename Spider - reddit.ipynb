{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit https://www.reddit.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "搜尋關鍵字 :  covid-19\n",
      "要顯示前幾篇? :  3\n",
      "要顯示多少留言? :  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------- TOP  1  start : ----------------------------------------------\n",
      "\n",
      "Title :  Empire State Building: “Starting tonight through the COVID-19 battle, our signature white lights will be replaced by the heartbeat of America with a white and red siren in the mast for heroic emergency workers on the front line of the fight.” \n",
      "\n",
      "Href :  /r/gifs/comments/fs4qsh/empire_state_building_starting_tonight_through/ \n",
      "\n",
      "\n",
      " technicolored_dreams  :\n",
      "\n",
      " Does it actually rotate that fast, or is the video sped up? It kinda made me nauseous.\n",
      "\n",
      " accountthrowawayjkkl  :\n",
      "\n",
      " Just looked out my window. It is that fast. It is super fucking creepy.\n",
      "\n",
      " rmit526  :\n",
      "\n",
      " It's like the eye of Sauron on methamphetamine\n",
      "\n",
      "\n",
      "---------------------------------------------- TOP  2  start : ----------------------------------------------\n",
      "\n",
      "Title :  More people have now died of COVID-19 (3,013) in America than as a result of 9/11 (2,996) \n",
      "\n",
      "Href :  /r/Coronavirus/comments/fs1myd/more_people_have_now_died_of_covid19_3013_in/ \n",
      "\n",
      "\n",
      " itchybuttorbit  :\n",
      "\n",
      " NYC really gets shafted in all the disasters\n",
      "\n",
      " Prodigism  :\n",
      "\n",
      " It's a ghost town out here man.\n",
      "\n",
      " appleparkfive  :\n",
      "\n",
      " NYC is just the perfect storm for this. The high population density (some areas of Manhattan have higher density than most huge cities), mixed with the fact that the virus can live on hard surfaces for a long time. The subway is basically a death trap right now.\n",
      "\n",
      "\n",
      "---------------------------------------------- TOP  3  start : ----------------------------------------------\n",
      "\n",
      "Title :  This is 90 year old Suzanne Hoylaerts of Belgium. She passed away after refusing a respirator to combat COVID-19 telling her doctors “Save it for the youngest who need it most, I’ve already had a beautiful life”. \n",
      "\n",
      "Href :  /r/nextfuckinglevel/comments/frzw8k/this_is_90_year_old_suzanne_hoylaerts_of_belgium/ \n",
      "\n",
      "\n",
      " AutoModerator  :\n",
      "\n",
      " Content posted to r/nextfuckinglevel should represent something impressive, be it an action, an object, a skill, a moment, a fact that is above all others. Posts should be able to elicit a reaction of \"that is next level\" from viewers. Avoid engaging in uncivil behavior in the comment section debating what is or isn't NFL.I am a bot, and this action was performed automatically. Please contact the moderators of this subreddit if you have any questions or concerns.\n",
      "\n",
      " Dom_33  :\n",
      "\n",
      " Sleep well.Edit: Thank you for the award 🙏🏾\n",
      "\n",
      " Leaderofmen  :\n",
      "\n",
      " Assuming OP means a ventilator.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "\n",
    "list_hrefs = []\n",
    "list_titles = []\n",
    "\n",
    "search_word = \"https://www.reddit.com/search/?q=\"+input(\"搜尋關鍵字 : \")\n",
    "top_x_threshold = input(\"要顯示前幾篇? : \")\n",
    "show_comment = input(\"要顯示多少留言? : \")\n",
    "\n",
    "while len(list_hrefs) == 0:\n",
    "    html = urlopen(search_word).read().decode('utf-8',errors='ignore')\n",
    "    soup = BeautifulSoup(html, features='lxml')\n",
    "    \n",
    "    a_href=soup.find_all('a', {'data-click-id': re.compile(\"body\")}) \n",
    "    for href in a_href:\n",
    "        list_hrefs.append(href['href'])\n",
    "\n",
    "    a_titles=soup.find_all('span', {'style': re.compile(\"font-weight:normal\")}) \n",
    "    for title in a_titles:\n",
    "        list_titles.append(title.text)\n",
    "    \n",
    "def repeat_run(i,show_,list_hrefs,list_titles):\n",
    "    top_x = i\n",
    "    list_href = list_hrefs\n",
    "    list_title = list_titles\n",
    "    show_comments = show_\n",
    "    if(top_x < int(top_x_threshold)):\n",
    "        try:\n",
    "            html = urlopen(\"https://www.reddit.com\"+ list_hrefs[top_x]).read().decode('utf-8',errors='ignore')\n",
    "            new_comment = []\n",
    "            if len(html) != 0:\n",
    "                soup = BeautifulSoup(html, features='lxml')\n",
    "                a_comments = soup.find_all('p')\n",
    "                for comment in a_comments:\n",
    "                    new_comment.append(comment.text)\n",
    "                a_tags=soup.find_all('script', {'id': re.compile(\"data\")}) \n",
    "                for tag in a_tags:\n",
    "                    from_position = 0\n",
    "                    author_lists = []\n",
    "                    author_start_position_lists = []\n",
    "                    for i in range(len(new_comment)):\n",
    "                        author_lists.append(tag.text[from_position+tag.text[from_position:].find(\"\\\"author\\\":\")+10:from_position+tag.text[from_position:].find(\"\\\",\\\"authorId\\\"\")])\n",
    "                        author_start_position_lists.append(from_position+tag.text[from_position:].find(\"\\\"author\\\":\")+10)\n",
    "                        from_position = from_position+tag.text[from_position:].find(\"\\\",\\\"authorId\\\"\")+12\n",
    "\n",
    "                    from_position = 0\n",
    "                    check_auther = 1\n",
    "                    comment_position_lists = []\n",
    "                    for i in range(len(new_comment)):\n",
    "                        if( from_position+tag.text[from_position:].find(\"}],\\\"e\\\"\") < author_start_position_lists[check_auther]):\n",
    "                            comment_position_lists.append(check_auther-1)\n",
    "                        else:\n",
    "                            check_auther+=1\n",
    "                            comment_position_lists.append(check_auther-1)\n",
    "                        from_position = from_position+tag.text[from_position:].find(\"}],\\\"e\\\"\")+7\n",
    "            \n",
    "            list_comment = ['' for i in range(len(set(comment_position_lists)))]\n",
    "            for sentences in range(len(new_comment)): #\n",
    "                list_comment[comment_position_lists[sentences]]+=new_comment[sentences]\n",
    "            print('---------------------------------------------- TOP ',top_x+1,' start : ----------------------------------------------\\n')\n",
    "            print('Title : ',list_title[top_x],'\\n')\n",
    "            print('Href : ',list_href[top_x],'\\n')\n",
    "            for each in range(show_comments):\n",
    "                print('\\n',author_lists[each],' :\\n\\n',list_comment[each])\n",
    "            print('\\n')\n",
    "            repeat_run(top_x+1,int(show_comments),list_hrefs,list_titles)\n",
    "        except:\n",
    "            repeat_run(top_x,int(show_comments),list_hrefs,list_titles)\n",
    "repeat_run(0,int(show_comment),list_hrefs,list_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
